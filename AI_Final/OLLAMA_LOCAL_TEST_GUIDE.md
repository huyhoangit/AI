# ğŸš€ HÆ¯á»šNG DáºªN TEST MODEL LOCAL OLLAMA

## ğŸ“¥ BÆ¯á»šC 1: CÃ€I Äáº¶T OLLAMA

### **Download & Install:**
1. **Truy cáº­p:** https://ollama.ai/download
2. **Download** phiÃªn báº£n cho Windows
3. **CÃ i Ä‘áº·t** file .exe Ä‘Ã£ táº£i vá»
4. **Khá»Ÿi Ä‘á»™ng** Ollama (tá»± Ä‘á»™ng cháº¡y background)

### **Kiá»ƒm tra cÃ i Ä‘áº·t:**
```bash
# Má»Ÿ Command Prompt hoáº·c PowerShell
ollama --version
```

## ğŸ¤– BÆ¯á»šC 2: Táº¢I MODEL

### **Táº£i model nháº¹ (khuyáº¿n nghá»‹):**
```bash
# Model nhá» (~3.8GB) - phÃ¹ há»£p mÃ¡y yáº¿u
ollama pull llama2:7b

# Hoáº·c model ráº¥t nhá» (~1.9GB)
ollama pull llama2:chat

# Model tiáº¿ng Viá»‡t (náº¿u cÃ³)
ollama pull vinallama
```

### **Test model:**
```bash
# Cháº¡y thá»­ model
ollama run llama2:7b

# Test cÃ¢u há»i
>>> Báº¡n lÃ  AI há»— trá»£ game Quoridor. Quoridor lÃ  gÃ¬?
```

## ğŸ® BÆ¯á»šC 3: Cáº¤U HÃŒNH UNITY

### **Trong HybridAIManager:**
1. **Äáº£m báº£o cáº¥u hÃ¬nh Ä‘Ãºng:**
   - `ollamaURL = "http://localhost:11434/api/generate"`
   - `ollamaModel = "llama2:7b"` (hoáº·c model báº¡n Ä‘Ã£ táº£i)
   - `primaryAPI = "ollama"`

### **Test trong Unity:**
1. **Táº¡o GameObject má»›i**
2. **Add component CompleteChatSystemSetup**
3. **Tick "Setup Complete System"**
4. **Play game vÃ  test chat**

## ğŸ” BÆ¯á»šC 4: DEBUG & KIá»‚M TRA

### **Kiá»ƒm tra Ollama Ä‘ang cháº¡y:**
```bash
# Check service
curl http://localhost:11434/api/version

# Hoáº·c trong browser
http://localhost:11434
```

### **Debug trong Unity Console:**
- TÃ¬m messages: `ğŸ”„ Trying ollama API...`
- Náº¿u thÃ nh cÃ´ng: `âœ… ollama API success`
- Náº¿u lá»—i: `âŒ ollama API failed`

## âš¡ QUICK TEST SCRIPT

### **Test nhanh Ollama tá»« Unity:**
```csharp
[ContextMenu("Test Ollama")]
public void TestOllama()
{
    GetAIResponse("Quoridor lÃ  gÃ¬?", (response, success) => {
        if (success)
            Debug.Log($"âœ… Ollama works: {response}");
        else
            Debug.LogError($"âŒ Ollama failed: {response}");
    });
}
```

## ğŸ› ï¸ TROUBLESHOOTING

### **Lá»—i thÆ°á»ng gáº·p:**

**1. Connection refused:**
- Ollama chÆ°a Ä‘Æ°á»£c start
- Cháº¡y: `ollama serve`

**2. Model not found:**
- Model chÆ°a Ä‘Æ°á»£c pull
- Cháº¡y: `ollama pull llama2:7b`

**3. Timeout:**
- TÄƒng `timeoutSeconds` trong HybridAIManager
- Model láº§n Ä‘áº§u cháº¡y cháº­m

**4. Empty response:**
- Check model cÃ³ Ä‘Ãºng format khÃ´ng
- Thá»­ model khÃ¡c: `ollama pull llama2:chat`

## ğŸ“Š KIá»‚M TRA HOáº T Äá»˜NG

### **Trong Unity Console sáº½ tháº¥y:**
```
ğŸ”§ Hybrid AI Manager initialized
Primary: ollama, Fallback: huggingface
ğŸ”„ Trying ollama API...
âœ… ollama API success
```

### **Náº¿u thÃ nh cÃ´ng:**
- Chat bot sáº½ tráº£ lá»i báº±ng model local
- KhÃ´ng cáº§n internet sau khi model Ä‘Ã£ táº£i
- Tá»‘c Ä‘á»™ phá»¥ thuá»™c vÃ o cáº¥u hÃ¬nh mÃ¡y

---

**ğŸ¯ READY TO TEST!** 
**Sau khi hoÃ n thÃ nh cÃ¡c bÆ°á»›c trÃªn, model local Ollama sáº½ hoáº¡t Ä‘á»™ng trong game!**
