using UnityEngine;

/// <summary>
/// Script test nhanh Ollama local model
/// ƒê·∫∑t v√†o GameObject ƒë·ªÉ test
/// </summary>
public class OllamaTestManager : MonoBehaviour
{
    [Header("Test Settings")]
    public bool autoTestOnStart = false;
    public string testQuestion = "Quoridor l√† g√¨? Gi·∫£i th√≠ch ng·∫Øn g·ªçn.";
    
    private HybridAIManager aiManager;
    
    void Start()
    {
        // T√¨m ho·∫∑c t·∫°o HybridAIManager
        aiManager = FindFirstObjectByType<HybridAIManager>();
        if (aiManager == null)
        {
            aiManager = gameObject.AddComponent<HybridAIManager>();
            Debug.Log("üîß Created HybridAIManager for testing");
        }
        
        if (autoTestOnStart)
        {
            Invoke("TestOllama", 2f); // ƒê·ª£i 2 gi√¢y cho AI manager kh·ªüi t·∫°o
        }
    }
    
    [ContextMenu("Test Ollama Local")]
    public void TestOllama()
    {
        if (aiManager == null)
        {
            Debug.LogError("‚ùå HybridAIManager not found!");
            return;
        }
        
        Debug.Log("üöÄ Testing Ollama local model...");
        Debug.Log($"Question: {testQuestion}");
        
        aiManager.GetAIResponse(testQuestion, OnTestResponse);
    }
    
    void OnTestResponse(string response, bool success)
    {
        if (success)
        {
            Debug.Log("‚úÖ OLLAMA TEST SUCCESSFUL!");
            Debug.Log($"Response: {response}");
            Debug.Log("üéâ Local model is working correctly!");
        }
        else
        {
            Debug.LogError("‚ùå OLLAMA TEST FAILED!");
            Debug.LogError($"Error: {response}");
            Debug.LogError("üí° Check Ollama installation and model download");
            ShowTroubleshootingTips();
        }
    }
    
    void ShowTroubleshootingTips()
    {
        Debug.Log("üõ†Ô∏è TROUBLESHOOTING TIPS:");
        Debug.Log("1. Check if Ollama is running: ollama serve");
        Debug.Log("2. Download model: ollama pull llama2:7b");
        Debug.Log("3. Test Ollama: curl http://localhost:11434/api/version");
        Debug.Log("4. Check model name in HybridAIManager settings");
    }
    
    [ContextMenu("Test Connection Only")]
    public void TestConnection()
    {
        StartCoroutine(TestOllamaConnection());
    }
    
    System.Collections.IEnumerator TestOllamaConnection()
    {
        Debug.Log("üîó Testing Ollama connection...");
        
        UnityEngine.Networking.UnityWebRequest request = 
            UnityEngine.Networking.UnityWebRequest.Get("http://localhost:11434/api/version");
        
        yield return request.SendWebRequest();
        
        if (request.result == UnityEngine.Networking.UnityWebRequest.Result.Success)
        {
            Debug.Log("‚úÖ Ollama server is running!");
            Debug.Log($"Response: {request.downloadHandler.text}");
        }
        else
        {
            Debug.LogError("‚ùå Cannot connect to Ollama server!");
            Debug.LogError($"Error: {request.error}");
            Debug.LogError("üí° Make sure Ollama is installed and running");
        }
        
        request.Dispose();
    }
    
    [ContextMenu("Show AI Status")]
    public void ShowAIStatus()
    {
        if (aiManager != null)
        {
            Debug.Log(aiManager.GetAPIStatus());
        }
        else
        {
            Debug.LogWarning("AI Manager not found");
        }
    }
    
    [ContextMenu("Quick Setup Guide")]
    public void ShowQuickSetup()
    {
        Debug.Log("üöÄ QUICK OLLAMA SETUP:");
        Debug.Log("1. Download: https://ollama.ai/download");
        Debug.Log("2. Install Ollama");
        Debug.Log("3. Run: ollama pull llama2:7b");
        Debug.Log("4. Run: ollama serve");
        Debug.Log("5. Click 'Test Ollama Local' in this component");
    }
}
